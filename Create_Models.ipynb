{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import pygame\n",
    "from stable_baselines3 import A2C\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.vec_env import VecFrameStack\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.env_util import make_atari_env\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env= gym.make(\"FrozenLake-v1\", desc=None, map_name = \"4x4\", is_slippery=False, render_mode = \"human\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gym\\utils\\passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game 1, reward?: 0.0 \n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"FrozenLake-v1\", desc=None, map_name = \"4x4\", is_slippery=False, render_mode = \"human\")\n",
    "pygame.init()\n",
    "observation, info = env.reset(seed=42)\n",
    "i = 1\n",
    "score = 0\n",
    "n = 20\n",
    "for _ in range(n):\n",
    "   env.render()\n",
    "   action = env.action_space.sample()  # this is where you would insert your policy\n",
    "   observation, reward, terminated, truncated, info = env.step(action)\n",
    "   score += reward\n",
    "   \n",
    "   if terminated or truncated:\n",
    "      print(\"game {}, reward?: {} \".format(i, score))\n",
    "      observation, info = env.reset()\n",
    "      i +=1 \n",
    "      \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"FrozenLake-v1\", desc=None, map_name = \"4x4\", is_slippery=False)\n",
    "env= DummyVecEnv([lambda: env])\n",
    "model = PPO('MlpPolicy', env, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 908  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 2    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 647       |\n",
      "|    iterations           | 2         |\n",
      "|    time_elapsed         | 6         |\n",
      "|    total_timesteps      | 4096      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.00382  |\n",
      "|    explained_variance   | 1         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -4.52e-05 |\n",
      "|    n_updates            | 310       |\n",
      "|    policy_gradient_loss | -2.32e-05 |\n",
      "|    value_loss           | 6.09e-16  |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 602          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 10           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002981581 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.00237     |\n",
      "|    explained_variance   | 1            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.000112    |\n",
      "|    n_updates            | 320          |\n",
      "|    policy_gradient_loss | -0.000792    |\n",
      "|    value_loss           | 1.48e-07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 566          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 14           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003593808 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.00223     |\n",
      "|    explained_variance   | 0.135        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.000145     |\n",
      "|    n_updates            | 330          |\n",
      "|    policy_gradient_loss | -0.000687    |\n",
      "|    value_loss           | 0.00205      |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 553           |\n",
      "|    iterations           | 5             |\n",
      "|    time_elapsed         | 18            |\n",
      "|    total_timesteps      | 10240         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.2118911e-09 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0023       |\n",
      "|    explained_variance   | 0.521         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -6.26e-05     |\n",
      "|    n_updates            | 340           |\n",
      "|    policy_gradient_loss | -3.19e-05     |\n",
      "|    value_loss           | 6.56e-06      |\n",
      "-------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 535       |\n",
      "|    iterations           | 6         |\n",
      "|    time_elapsed         | 22        |\n",
      "|    total_timesteps      | 12288     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3072471 |\n",
      "|    clip_fraction        | 0.104     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.0297   |\n",
      "|    explained_variance   | 0.998     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0179   |\n",
      "|    n_updates            | 350       |\n",
      "|    policy_gradient_loss | -0.021    |\n",
      "|    value_loss           | 2.09e-08  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 527       |\n",
      "|    iterations           | 7         |\n",
      "|    time_elapsed         | 27        |\n",
      "|    total_timesteps      | 14336     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0936897 |\n",
      "|    clip_fraction        | 0.329     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.428    |\n",
      "|    explained_variance   | 0.0416    |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0603   |\n",
      "|    n_updates            | 360       |\n",
      "|    policy_gradient_loss | -0.0355   |\n",
      "|    value_loss           | 0.00218   |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 527         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 31          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019689452 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.278      |\n",
      "|    explained_variance   | 0.147       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0438     |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.047      |\n",
      "|    value_loss           | 0.00101     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 524         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 35          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017395975 |\n",
      "|    clip_fraction        | 0.349       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.265      |\n",
      "|    explained_variance   | 0.343       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0541     |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0531     |\n",
      "|    value_loss           | 0.000445    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 522         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 39          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008917699 |\n",
      "|    clip_fraction        | 0.288       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.202      |\n",
      "|    explained_variance   | 0.606       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.058      |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0462     |\n",
      "|    value_loss           | 0.000211    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 519        |\n",
      "|    iterations           | 11         |\n",
      "|    time_elapsed         | 43         |\n",
      "|    total_timesteps      | 22528      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06934557 |\n",
      "|    clip_fraction        | 0.254      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.106     |\n",
      "|    explained_variance   | 0.73       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0514    |\n",
      "|    n_updates            | 400        |\n",
      "|    policy_gradient_loss | -0.0437    |\n",
      "|    value_loss           | 0.000119   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 514         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 47          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.085126355 |\n",
      "|    clip_fraction        | 0.0282      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0112     |\n",
      "|    explained_variance   | 0.943       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0311     |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0244     |\n",
      "|    value_loss           | 1.6e-05     |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 508           |\n",
      "|    iterations           | 13            |\n",
      "|    time_elapsed         | 52            |\n",
      "|    total_timesteps      | 26624         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00021586617 |\n",
      "|    clip_fraction        | 0.000781      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.00345      |\n",
      "|    explained_variance   | 0.996         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.000155      |\n",
      "|    n_updates            | 420           |\n",
      "|    policy_gradient_loss | -0.001        |\n",
      "|    value_loss           | 5.44e-07      |\n",
      "-------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 507        |\n",
      "|    iterations           | 14         |\n",
      "|    time_elapsed         | 56         |\n",
      "|    total_timesteps      | 28672      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05495185 |\n",
      "|    clip_fraction        | 0.0218     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0227    |\n",
      "|    explained_variance   | 1          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0352    |\n",
      "|    n_updates            | 430        |\n",
      "|    policy_gradient_loss | -0.00652   |\n",
      "|    value_loss           | 2.58e-09   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 506         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 60          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015085783 |\n",
      "|    clip_fraction        | 0.306       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.237      |\n",
      "|    explained_variance   | 0.565       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0534     |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0495     |\n",
      "|    value_loss           | 0.000235    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 503          |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 65           |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062570674 |\n",
      "|    clip_fraction        | 0.216        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.186       |\n",
      "|    explained_variance   | 0.64         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0523      |\n",
      "|    n_updates            | 450          |\n",
      "|    policy_gradient_loss | -0.0433      |\n",
      "|    value_loss           | 0.00016      |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 502        |\n",
      "|    iterations           | 17         |\n",
      "|    time_elapsed         | 69         |\n",
      "|    total_timesteps      | 34816      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06641343 |\n",
      "|    clip_fraction        | 0.241      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0892    |\n",
      "|    explained_variance   | 0.802      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0322    |\n",
      "|    n_updates            | 460        |\n",
      "|    policy_gradient_loss | -0.0388    |\n",
      "|    value_loss           | 7.63e-05   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 503        |\n",
      "|    iterations           | 18         |\n",
      "|    time_elapsed         | 73         |\n",
      "|    total_timesteps      | 36864      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06526719 |\n",
      "|    clip_fraction        | 0.0193     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.00748   |\n",
      "|    explained_variance   | 0.941      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0339    |\n",
      "|    n_updates            | 470        |\n",
      "|    policy_gradient_loss | -0.027     |\n",
      "|    value_loss           | 1.47e-05   |\n",
      "----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 502           |\n",
      "|    iterations           | 19            |\n",
      "|    time_elapsed         | 77            |\n",
      "|    total_timesteps      | 38912         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.9546437e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.00212      |\n",
      "|    explained_variance   | 0.999         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.000284     |\n",
      "|    n_updates            | 480           |\n",
      "|    policy_gradient_loss | -0.000123     |\n",
      "|    value_loss           | 1.12e-07      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 501           |\n",
      "|    iterations           | 20            |\n",
      "|    time_elapsed         | 81            |\n",
      "|    total_timesteps      | 40960         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.2265747e-05 |\n",
      "|    clip_fraction        | 0.000391      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0015       |\n",
      "|    explained_variance   | 0.999         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 5.68e-05      |\n",
      "|    n_updates            | 490           |\n",
      "|    policy_gradient_loss | -0.00059      |\n",
      "|    value_loss           | 2.57e-07      |\n",
      "-------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 501       |\n",
      "|    iterations           | 21        |\n",
      "|    time_elapsed         | 85        |\n",
      "|    total_timesteps      | 43008     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.00148  |\n",
      "|    explained_variance   | 1         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -5.07e-05 |\n",
      "|    n_updates            | 500       |\n",
      "|    policy_gradient_loss | -1.86e-05 |\n",
      "|    value_loss           | 3.58e-10  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 501       |\n",
      "|    iterations           | 22        |\n",
      "|    time_elapsed         | 89        |\n",
      "|    total_timesteps      | 45056     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.0014   |\n",
      "|    explained_variance   | 1         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -5.25e-05 |\n",
      "|    n_updates            | 510       |\n",
      "|    policy_gradient_loss | -2.54e-05 |\n",
      "|    value_loss           | 1.24e-13  |\n",
      "---------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 502           |\n",
      "|    iterations           | 23            |\n",
      "|    time_elapsed         | 93            |\n",
      "|    total_timesteps      | 47104         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00021541104 |\n",
      "|    clip_fraction        | 0.000439      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.00142      |\n",
      "|    explained_variance   | 0.135         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 9.35e-06      |\n",
      "|    n_updates            | 520           |\n",
      "|    policy_gradient_loss | -0.000697     |\n",
      "|    value_loss           | 0.00206       |\n",
      "-------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 504       |\n",
      "|    iterations           | 24        |\n",
      "|    time_elapsed         | 97        |\n",
      "|    total_timesteps      | 49152     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.0018   |\n",
      "|    explained_variance   | 0.709     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -1.14e-05 |\n",
      "|    n_updates            | 530       |\n",
      "|    policy_gradient_loss | -6.48e-06 |\n",
      "|    value_loss           | 3.68e-06  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 505        |\n",
      "|    iterations           | 25         |\n",
      "|    time_elapsed         | 101        |\n",
      "|    total_timesteps      | 51200      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16570202 |\n",
      "|    clip_fraction        | 0.0522     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0299    |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0369    |\n",
      "|    n_updates            | 540        |\n",
      "|    policy_gradient_loss | -0.014     |\n",
      "|    value_loss           | 2.65e-08   |\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model.learn(total_timesteps=50000)\n",
    "model.save(\"FrozenLake_model_testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\stable_baselines3\\common\\vec_env\\base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.\n",
      "  warnings.warn(\"You tried to call render() but no `render_mode` was passed to the env constructor.\")\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error: Unexpected observation shape (1, 1) for Discrete environment, please use () or (n_env,) for the observation shape.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[39m# Preprocess the observation to ensure it's a numeric ndarray\u001b[39;00m\n\u001b[0;32m     25\u001b[0m observation \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([observation])\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mfloat32)\n\u001b[1;32m---> 27\u001b[0m action, _ \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(observation, deterministic\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m     28\u001b[0m observation, reward, terminated, _ \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mstep(action[\u001b[39m0\u001b[39m])  \u001b[39m# Take the first action from the batch\u001b[39;00m\n\u001b[0;32m     29\u001b[0m score \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m reward\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\stable_baselines3\\common\\base_class.py:555\u001b[0m, in \u001b[0;36mBaseAlgorithm.predict\u001b[1;34m(self, observation, state, episode_start, deterministic)\u001b[0m\n\u001b[0;32m    535\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\n\u001b[0;32m    536\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    537\u001b[0m     observation: Union[np\u001b[39m.\u001b[39mndarray, Dict[\u001b[39mstr\u001b[39m, np\u001b[39m.\u001b[39mndarray]],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    540\u001b[0m     deterministic: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    541\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[np\u001b[39m.\u001b[39mndarray, Optional[Tuple[np\u001b[39m.\u001b[39mndarray, \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m]]]:\n\u001b[0;32m    542\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    543\u001b[0m \u001b[39m    Get the policy action from an observation (and optional hidden state).\u001b[39;00m\n\u001b[0;32m    544\u001b[0m \u001b[39m    Includes sugar-coating to handle different observations (e.g. normalizing images).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[39m        (used in recurrent policies)\u001b[39;00m\n\u001b[0;32m    554\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 555\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpolicy\u001b[39m.\u001b[39;49mpredict(observation, state, episode_start, deterministic)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\stable_baselines3\\common\\policies.py:346\u001b[0m, in \u001b[0;36mBasePolicy.predict\u001b[1;34m(self, observation, state, episode_start, deterministic)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[39m# Switch to eval mode (this affects batch norm / dropout)\u001b[39;00m\n\u001b[0;32m    344\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_training_mode(\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m--> 346\u001b[0m observation, vectorized_env \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobs_to_tensor(observation)\n\u001b[0;32m    348\u001b[0m \u001b[39mwith\u001b[39;00m th\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m    349\u001b[0m     actions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_predict(observation, deterministic\u001b[39m=\u001b[39mdeterministic)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\stable_baselines3\\common\\policies.py:264\u001b[0m, in \u001b[0;36mBaseModel.obs_to_tensor\u001b[1;34m(self, observation)\u001b[0m\n\u001b[0;32m    260\u001b[0m     observation \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(observation)\n\u001b[0;32m    262\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(observation, \u001b[39mdict\u001b[39m):\n\u001b[0;32m    263\u001b[0m     \u001b[39m# Dict obs need to be handled separately\u001b[39;00m\n\u001b[1;32m--> 264\u001b[0m     vectorized_env \u001b[39m=\u001b[39m is_vectorized_observation(observation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobservation_space)\n\u001b[0;32m    265\u001b[0m     \u001b[39m# Add batch dimension if needed\u001b[39;00m\n\u001b[0;32m    266\u001b[0m     observation \u001b[39m=\u001b[39m observation\u001b[39m.\u001b[39mreshape((\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobservation_space\u001b[39m.\u001b[39mshape))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\stable_baselines3\\common\\utils.py:399\u001b[0m, in \u001b[0;36mis_vectorized_observation\u001b[1;34m(observation, observation_space)\u001b[0m\n\u001b[0;32m    397\u001b[0m \u001b[39mfor\u001b[39;00m space_type, is_vec_obs_func \u001b[39min\u001b[39;00m is_vec_obs_func_dict\u001b[39m.\u001b[39mitems():\n\u001b[0;32m    398\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(observation_space, space_type):\n\u001b[1;32m--> 399\u001b[0m         \u001b[39mreturn\u001b[39;00m is_vec_obs_func(observation, observation_space)\n\u001b[0;32m    400\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    401\u001b[0m     \u001b[39m# for-else happens if no break is called\u001b[39;00m\n\u001b[0;32m    402\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mError: Cannot determine if the observation is vectorized with the space type \u001b[39m\u001b[39m{\u001b[39;00mobservation_space\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\stable_baselines3\\common\\utils.py:287\u001b[0m, in \u001b[0;36mis_vectorized_discrete_observation\u001b[1;34m(observation, observation_space)\u001b[0m\n\u001b[0;32m    285\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    286\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 287\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    288\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mError: Unexpected observation shape \u001b[39m\u001b[39m{\u001b[39;00mobservation\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m for \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    289\u001b[0m         \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mDiscrete environment, please use () or (n_env,) for the observation shape.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    290\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Error: Unexpected observation shape (1, 1) for Discrete environment, please use () or (n_env,) for the observation shape."
     ]
    }
   ],
   "source": [
    "import gym\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "import numpy as np\n",
    "\n",
    "# Create the Gym environment\n",
    "env = gym.make(\"FrozenLake-v1\", desc=None, map_name=\"4x4\", is_slippery=False, render_mode=\"human\")\n",
    "\n",
    "# Wrap the environment in DummyVecEnv to set the random seed\n",
    "env = DummyVecEnv([lambda: env])\n",
    "env.seed(42)  # Set the random seed for reproducibility\n",
    "\n",
    "# Load the pre-trained PPO model\n",
    "model = PPO.load(\"FrozenLake_model_testing\")\n",
    "\n",
    "# Play the game once using the trained model and display the total reward\n",
    "observation = env.reset()\n",
    "score = 0\n",
    "terminated = False\n",
    "\n",
    "while not terminated:\n",
    "    env.render()\n",
    "\n",
    "    # Preprocess the observation to ensure it's a numeric ndarray\n",
    "    observation = np.array([observation]).astype(np.float32)\n",
    "\n",
    "    action, _ = model.predict(observation, deterministic=True)\n",
    "    observation, reward, terminated, _ = env.step(action[0])  # Take the first action from the batch\n",
    "    score += reward\n",
    "\n",
    "print(\"Total Reward: {}\".format(score))\n",
    "\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
